# 面试算法题

## 十道海量数据处理面试题与十个方法大总结 

#### 1.海量日志数据，提取出某日访问百度次数最多的那个IP？

解决方案: 
1.分治 + IP取模
2.如何出现不均衡的情况，换个HASH函数继续分


#### 2. 1kw个串，每个串不超过256字节，求出现次数最多的前10个串，不超过1个G

1.分治 + 串Hash取模
2.topK问题

#### 3. 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词？

1.分治 + 串Hash取模
2.topK问题


#### 4. 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。
1.分治 + 串Hash取模，到10个文件
2.排序输出到10个文件
3.归并排序

#### 5. 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？
1. 分治 + 串Hash取模，到10个文件
2. 挨个文件统计

允许一定重复: 布隆过滤器

#### 6. 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。
1. 分治 + 串Hash取模，到10个文件
2. 统计次数，指输出一次的，就是不重复的


#### 7. 腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？
1. 分治 + 串Hash取模，到1000个文件
2. 处理单个文件

允许出现误差: 布隆过滤器


#### 8.总结一下有那些方案?
1.hash取模分治
2.布隆过滤器
3.位图
4.大数据技术
5.字典树来做统计
6.堆求topk




